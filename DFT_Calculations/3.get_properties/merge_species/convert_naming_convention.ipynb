{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Run this after all the GP notebooks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This copy all the summary file and merge them by tagging _anion and _opensheel to the corresponding species properties\n",
    "### Then it convert from Tom naming convenction to Leah naming convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "postprocessed_results_folder = '5.postprocessed_results'\n",
    "\n",
    "anion_summary_file = gp_anion + os.sep + postprocessed_results_folder + Summary_Properties_all.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the mapping from smiles_with_mapping.xlsx\n",
    "df = pd.read_excel(\"smiles_with_mapping.xlsx\", header=0)\n",
    "df = df[[\"id\", \"mapping\"]]\n",
    "\n",
    "# Convert the mapping column to a dictionary with id being key, mapping being value\n",
    "mapping_dict_from_tom_to_leah = dict(zip(df[\"id\"], df[\"mapping\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pyrd1': 'Het001',\n",
       " 'pyrd2': 'Het002',\n",
       " 'pyrd3': 'Het003',\n",
       " 'pyrmd1': 'Het004',\n",
       " 'pyrmd2': 'Het005',\n",
       " 'pyrz1': 'Het006',\n",
       " 'pyrd4': 'Het007',\n",
       " 'pyrd5': 'Het008',\n",
       " 'pyrd6': 'Het009',\n",
       " 'pyrd7': 'Het010',\n",
       " 'pyrd8': 'Het011',\n",
       " 'pyrd9': 'Het012',\n",
       " 'pyrmd3': 'Het013',\n",
       " 'pyrmd4': 'Het014',\n",
       " 'pyrz2': 'Het015',\n",
       " 'pyrd10': 'Het016',\n",
       " 'pyrd11': 'Het017',\n",
       " 'pyrd12': 'Het018',\n",
       " 'pyrd13': 'Het019',\n",
       " 'pyrd14': 'Het020',\n",
       " 'pyrd15': 'Het021',\n",
       " 'pyrmd5': 'Het022',\n",
       " 'pyrmd6': 'Het023',\n",
       " 'pyrmd7': 'Het024',\n",
       " 'pyrz3': 'Het025',\n",
       " 'pyrdz1': 'Het026',\n",
       " 'pyrdz2': 'Het027',\n",
       " 'pyrd16': 'Het028',\n",
       " 'pyrd17': 'Het029',\n",
       " 'pyrd18': 'Het030',\n",
       " 'pyrmd8': 'Het031',\n",
       " 'pyrmd9': 'Het032',\n",
       " 'pyrmd10': 'Het033',\n",
       " 'pyrz4': 'Het034',\n",
       " 'pyrdz3': 'Het035'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict_from_tom_to_leah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! define all the files you need to convert\n",
    "files = [\n",
    "    \"closed_shell_properties_postprocessed_Tom.xlsx\",\n",
    "    \"openshell_properties_postprocessed_Tom.xlsx\",\n",
    "    \"anion_properties_postprocessed_Tom.xlsx\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saving to closed_shell_properties_postprocessed_Leah.xlsx'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'saving to openshell_properties_postprocessed_Leah.xlsx'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'saving to anion_properties_postprocessed_Leah.xlsx'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read each file\n",
    "for file in files:\n",
    "    content = pd.read_excel(file, header=0)\n",
    "    # display(content)\n",
    "    # what we care is the Compound_Name column\n",
    "    # go over row, use regular expression to match the column with the key from mapping_dict_from_tom_to_leah\n",
    "    # if found, replace the value with the value from mapping_dict_from_tom_to_leah\n",
    "    for index, row in content.iterrows():\n",
    "        for key, value in mapping_dict_from_tom_to_leah.items():\n",
    "            if key in row[\"Compound_Name\"]:\n",
    "                content.at[index, \"Compound_Name\"] = row[\"Compound_Name\"].replace(\n",
    "                    key, value\n",
    "                )\n",
    "    # then sort the row in ascend by Compound_Name, use this \"\\D+(\\d+)\" to find the number in the string\n",
    "    content[\"Compound_numbering\"] = content[\"Compound_Name\"].str.extract(\"(\\d+)\", expand=False).astype(int)\n",
    "    content = content.sort_values(by=\"Compound_numbering\")\n",
    "    content = content.drop(columns=[\"Compound_numbering\"])\n",
    "    # reset the index\n",
    "    content = content.reset_index(drop=True)\n",
    "    # display(content)\n",
    "    # split the filename by \"_\" drop the last part, add \"Leah\" and join everything back\n",
    "    new_filename = \"_\".join(file.split(\"_\")[:-1]) + \"_Leah.xlsx\"\n",
    "    display(f\"saving to {new_filename}\")\n",
    "    # save the file\n",
    "    content.to_excel(new_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

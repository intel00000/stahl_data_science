{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"font-family: Arial; color: gold; font-weight: bold;\">**create by Tom Tan in 8.30.2024** </p>\n",
    "##### The idea is to create one notebook for each prefix. You only need to define the prefix in the follow cell and the notebook will do the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# **1. Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "\n",
    "import get_properties_functions_for_WI as gp\n",
    "\n",
    "import importlib\n",
    "\n",
    "common_structure_folder = \"1.common_structure\"\n",
    "log_files_folder = \"2.log_files\"\n",
    "sdf_files_folder = \"3.sdf_files\"\n",
    "temp_folder = \"temp\"\n",
    "output_folder = \"4.atom_mappings\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# **2. Import the atom map from preprocess notebook**\n",
    "### <p style=\"font-family: Arial; color: gold; font-weight: bold;\"> **!!!User input required, Change the prefix to the one you want to handle.** </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_name</th>\n",
       "      <th>C3</th>\n",
       "      <th>N4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>N7</th>\n",
       "      <th>C2</th>\n",
       "      <th>C1</th>\n",
       "      <th>H1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.log_files\\pyrz1_conf-1</td>\n",
       "      <td>C11</td>\n",
       "      <td>N10</td>\n",
       "      <td>C5</td>\n",
       "      <td>C4</td>\n",
       "      <td>N3</td>\n",
       "      <td>C2</td>\n",
       "      <td>C1</td>\n",
       "      <td>H12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.log_files\\pyrz2_conf-1</td>\n",
       "      <td>C12</td>\n",
       "      <td>N11</td>\n",
       "      <td>C10</td>\n",
       "      <td>C5</td>\n",
       "      <td>N4</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "      <td>H16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.log_files\\pyrz2_conf-2</td>\n",
       "      <td>C12</td>\n",
       "      <td>N11</td>\n",
       "      <td>C10</td>\n",
       "      <td>C5</td>\n",
       "      <td>N4</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "      <td>H16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.log_files\\pyrz2_conf-3</td>\n",
       "      <td>C12</td>\n",
       "      <td>N11</td>\n",
       "      <td>C10</td>\n",
       "      <td>C5</td>\n",
       "      <td>N4</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "      <td>H16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.log_files\\pyrz3_conf-1</td>\n",
       "      <td>C7</td>\n",
       "      <td>N6</td>\n",
       "      <td>C5</td>\n",
       "      <td>C4</td>\n",
       "      <td>N3</td>\n",
       "      <td>C2</td>\n",
       "      <td>C1</td>\n",
       "      <td>H8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   log_name   C3   N4   C5  C6  N7  C2  C1   H1\n",
       "0  2.log_files\\pyrz1_conf-1  C11  N10   C5  C4  N3  C2  C1  H12\n",
       "1  2.log_files\\pyrz2_conf-1  C12  N11  C10  C5  N4  C3  C2  H16\n",
       "2  2.log_files\\pyrz2_conf-2  C12  N11  C10  C5  N4  C3  C2  H16\n",
       "3  2.log_files\\pyrz2_conf-3  C12  N11  C10  C5  N4  C3  C2  H16\n",
       "4  2.log_files\\pyrz3_conf-1   C7   N6   C5  C4  N3  C2  C1   H8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prefix = \"pyrz\"\n",
    "\n",
    "atom_mappings = output_folder + os.sep + prefix + \"_atom_map.xlsx\"\n",
    "\n",
    "atom_map_df = pd.read_excel(\n",
    "    atom_mappings, \"Sheet1\", index_col=0, header=0, engine=\"openpyxl\"\n",
    ")\n",
    "\n",
    "# add the log_files_folder before all the log_names cells\n",
    "atom_map_df[\"log_name\"] = log_files_folder + os.sep + atom_map_df[\"log_name\"]\n",
    "\n",
    "display(atom_map_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Define Properties to Collect**\n",
    "### <p style=\"font-family: Arial; color: gold\"> !!!User input required, Change/comment the properties block to the one you want to collect. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Bond Order function has completed.\n",
      "Mapped Atoms: {'C1': 'C1', 'C2': 'C2'}\n",
      "Mapped Atoms: {'C2': 'C1', 'C3': 'C2'}\n",
      "Mapped Atoms: {'C2': 'C1', 'C3': 'C2'}\n",
      "Mapped Atoms: {'C2': 'C1', 'C3': 'C2'}\n",
      "Mapped Atoms: {'C1': 'C1', 'C2': 'C2'}\n",
      "Mapped Atoms: {'C2': 'C1', 'C3': 'C2'}\n",
      "Mapped Atoms: {'C2': 'C1', 'C3': 'C2'}\n",
      "Natural Atomic Valencies function has completed for ['C1', 'C2']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_name</th>\n",
       "      <th>C3</th>\n",
       "      <th>N4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>N7</th>\n",
       "      <th>C2</th>\n",
       "      <th>C1</th>\n",
       "      <th>H1</th>\n",
       "      <th>C1_C2_bond_order_total</th>\n",
       "      <th>...</th>\n",
       "      <th>C1_C2_bond_order_ionic</th>\n",
       "      <th>C2_C3_bond_order_total</th>\n",
       "      <th>C2_C3_bond_order_covalent</th>\n",
       "      <th>C2_C3_bond_order_ionic</th>\n",
       "      <th>C1_Co-Valency</th>\n",
       "      <th>C1_Electro-Valency</th>\n",
       "      <th>C1_FormalCharge</th>\n",
       "      <th>C2_Co-Valency</th>\n",
       "      <th>C2_Electro-Valency</th>\n",
       "      <th>C2_FormalCharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.log_files\\pyrz1_conf-1</td>\n",
       "      <td>C11</td>\n",
       "      <td>N10</td>\n",
       "      <td>C5</td>\n",
       "      <td>C4</td>\n",
       "      <td>N3</td>\n",
       "      <td>C2</td>\n",
       "      <td>C1</td>\n",
       "      <td>H12</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.2608</td>\n",
       "      <td>0.6942</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>3.5551</td>\n",
       "      <td>0.3587</td>\n",
       "      <td>-0.0590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.log_files\\pyrz2_conf-1</td>\n",
       "      <td>C12</td>\n",
       "      <td>N11</td>\n",
       "      <td>C10</td>\n",
       "      <td>C5</td>\n",
       "      <td>N4</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "      <td>H16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9416</td>\n",
       "      <td>0.9340</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>3.4897</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>-0.0064</td>\n",
       "      <td>3.5349</td>\n",
       "      <td>0.3586</td>\n",
       "      <td>-0.0704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.log_files\\pyrz2_conf-2</td>\n",
       "      <td>C12</td>\n",
       "      <td>N11</td>\n",
       "      <td>C10</td>\n",
       "      <td>C5</td>\n",
       "      <td>N4</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "      <td>H16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9558</td>\n",
       "      <td>0.9401</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>3.4853</td>\n",
       "      <td>0.4759</td>\n",
       "      <td>-0.0050</td>\n",
       "      <td>3.5339</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>-0.0696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.log_files\\pyrz2_conf-3</td>\n",
       "      <td>C12</td>\n",
       "      <td>N11</td>\n",
       "      <td>C10</td>\n",
       "      <td>C5</td>\n",
       "      <td>N4</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "      <td>H16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9557</td>\n",
       "      <td>0.9401</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>3.4853</td>\n",
       "      <td>0.4759</td>\n",
       "      <td>-0.0050</td>\n",
       "      <td>3.5339</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>-0.0696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.log_files\\pyrz3_conf-1</td>\n",
       "      <td>C7</td>\n",
       "      <td>N6</td>\n",
       "      <td>C5</td>\n",
       "      <td>C4</td>\n",
       "      <td>N3</td>\n",
       "      <td>C2</td>\n",
       "      <td>C1</td>\n",
       "      <td>H8</td>\n",
       "      <td>0.9645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.2699</td>\n",
       "      <td>0.6883</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>3.6053</td>\n",
       "      <td>0.3484</td>\n",
       "      <td>-0.0088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.log_files\\pyrz4_conf-1</td>\n",
       "      <td>C8</td>\n",
       "      <td>N7</td>\n",
       "      <td>C6</td>\n",
       "      <td>C5</td>\n",
       "      <td>N4</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "      <td>H12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9472</td>\n",
       "      <td>0.9350</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>3.4960</td>\n",
       "      <td>0.4711</td>\n",
       "      <td>-0.0115</td>\n",
       "      <td>3.5872</td>\n",
       "      <td>0.3417</td>\n",
       "      <td>-0.0218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.log_files\\pyrz4_conf-2</td>\n",
       "      <td>C8</td>\n",
       "      <td>N7</td>\n",
       "      <td>C6</td>\n",
       "      <td>C5</td>\n",
       "      <td>N4</td>\n",
       "      <td>C3</td>\n",
       "      <td>C2</td>\n",
       "      <td>H12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9546</td>\n",
       "      <td>0.9389</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>3.4956</td>\n",
       "      <td>0.4742</td>\n",
       "      <td>-0.0063</td>\n",
       "      <td>3.5927</td>\n",
       "      <td>0.3395</td>\n",
       "      <td>-0.0229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   log_name   C3   N4   C5  C6  N7  C2  C1   H1  \\\n",
       "0  2.log_files\\pyrz1_conf-1  C11  N10   C5  C4  N3  C2  C1  H12   \n",
       "1  2.log_files\\pyrz2_conf-1  C12  N11  C10  C5  N4  C3  C2  H16   \n",
       "2  2.log_files\\pyrz2_conf-2  C12  N11  C10  C5  N4  C3  C2  H16   \n",
       "3  2.log_files\\pyrz2_conf-3  C12  N11  C10  C5  N4  C3  C2  H16   \n",
       "4  2.log_files\\pyrz3_conf-1   C7   N6   C5  C4  N3  C2  C1   H8   \n",
       "5  2.log_files\\pyrz4_conf-1   C8   N7   C6  C5  N4  C3  C2  H12   \n",
       "6  2.log_files\\pyrz4_conf-2   C8   N7   C6  C5  N4  C3  C2  H12   \n",
       "\n",
       "  C1_C2_bond_order_total  ... C1_C2_bond_order_ionic C2_C3_bond_order_total  \\\n",
       "0                 0.9605  ...                 0.0165                    NaN   \n",
       "1                    NaN  ...                    NaN                 0.9416   \n",
       "2                    NaN  ...                    NaN                 0.9558   \n",
       "3                    NaN  ...                    NaN                 0.9557   \n",
       "4                 0.9645  ...                 0.0181                    NaN   \n",
       "5                    NaN  ...                    NaN                 0.9472   \n",
       "6                    NaN  ...                    NaN                 0.9546   \n",
       "\n",
       "  C2_C3_bond_order_covalent C2_C3_bond_order_ionic C1_Co-Valency  \\\n",
       "0                       NaN                    NaN        3.2608   \n",
       "1                    0.9340                 0.0076        3.4897   \n",
       "2                    0.9401                 0.0156        3.4853   \n",
       "3                    0.9401                 0.0156        3.4853   \n",
       "4                       NaN                    NaN        3.2699   \n",
       "5                    0.9350                 0.0122        3.4960   \n",
       "6                    0.9389                 0.0156        3.4956   \n",
       "\n",
       "  C1_Electro-Valency C1_FormalCharge C2_Co-Valency C2_Electro-Valency  \\\n",
       "0             0.6942          0.0014        3.5551             0.3587   \n",
       "1             0.4708         -0.0064        3.5349             0.3586   \n",
       "2             0.4759         -0.0050        3.5339             0.3596   \n",
       "3             0.4759         -0.0050        3.5339             0.3596   \n",
       "4             0.6883          0.0010        3.6053             0.3484   \n",
       "5             0.4711         -0.0115        3.5872             0.3417   \n",
       "6             0.4742         -0.0063        3.5927             0.3395   \n",
       "\n",
       "  C2_FormalCharge  \n",
       "0         -0.0590  \n",
       "1         -0.0704  \n",
       "2         -0.0696  \n",
       "3         -0.0696  \n",
       "4         -0.0088  \n",
       "5         -0.0218  \n",
       "6         -0.0229  \n",
       "\n",
       "[7 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importlib.reload(gp)\n",
    "df = atom_map_df.copy()\n",
    "\n",
    "natural_bond_order_list = [[\"C1\", \"C2\"]]\n",
    "# for testing, only use the first row\n",
    "df = gp.get_natural_bond_order(df, natural_bond_order_list)\n",
    "\n",
    "natural_atomic_valencies_list = [\"C1\", \"C2\"]\n",
    "df = gp.get_natural_atomic_valencies(df, natural_atomic_valencies_list)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this box has functions to choose from\n",
    "df = atom_map_df\n",
    "\n",
    "# ---------------GoodVibes Engergies---------------\n",
    "# uses the GoodVibes 2021 Branch (Jupyter Notebook Compatible)\n",
    "# calculates the quasi harmonic corrected G(T) and single point corrected G(T) as well as other thermodynamic properties\n",
    "# inputs: dataframe, temperature\n",
    "df = gp.get_goodvibes_e(df, 298.15)\n",
    "\n",
    "# ---------------Frontier Orbitals-----------------\n",
    "# E(HOMO), E(LUMO), mu(chemical potential or negative of molecular electronegativity), eta(hardness/softness), omega(electrophilicity index)\n",
    "df = gp.get_frontierorbs(df)\n",
    "\n",
    "# ---------------Polarizability--------------------\n",
    "# Exact polarizability\n",
    "df = gp.get_polarizability(df)\n",
    "\n",
    "# ---------------Dipole----------------------------\n",
    "# Total dipole moment magnitude in Debye\n",
    "df = gp.get_dipole(df)\n",
    "\n",
    "# ---------------Volume----------------------------\n",
    "# Molar volume\n",
    "# requires the Gaussian keyword = \"volume\" in the .com file\n",
    "df = gp.get_volume(df)\n",
    "\n",
    "# ---------------SASA------------------------------\n",
    "# Uses morfeus to calculat sovlent accessible surface area and the volume under the SASA\n",
    "df = gp.get_SASA(df)\n",
    "\n",
    "# ---------------NBO-------------------------------\n",
    "# natural charge from NBO\n",
    "# requires the Gaussian keyword = \"pop=nbo7\" in the .com file\n",
    "nbo_list = [\"C1\", \"C2\"]\n",
    "df = gp.get_nbo(df, nbo_list)\n",
    "\n",
    "# ---------------NMR-------------------------------\n",
    "# isotropic NMR shift\n",
    "# requires the Gaussian keyword = \"nmr=giao\" in the .com file\n",
    "nmr_list = [\"C1\", \"C2\"]\n",
    "df = gp.get_nmr(df, nmr_list)\n",
    "\n",
    "# ---------------Distance--------------------------\n",
    "# distance between 2 atoms\n",
    "dist_list_of_lists = [[\"C1\", \"C2\"]]\n",
    "df = gp.get_distance(df, dist_list_of_lists)\n",
    "\n",
    "# ---------------Angle-----------------------------\n",
    "# angle between 3 atoms\n",
    "# angle_list_of_lists = [[\"C5\", \"N1\", \"C1\"]]\n",
    "# df = gp.get_angles(df, angle_list_of_lists)\n",
    "\n",
    "# ---------------Dihedral--------------------------\n",
    "# dihedral angle between 4 atoms\n",
    "# dihedral_list_of_lists = [[\"C4\", \"C5\", \"N1\", \"C1\"], [\"C2\", \"C1\", \"N1\", \"C5\"]]\n",
    "# df = gp.get_dihedral(df, dihedral_list_of_lists)\n",
    "\n",
    "# ---------------Vbur Scan-------------------------\n",
    "# uses morfeus to calculate the buried volume at a series of radii (including hydrogens)\n",
    "# inputs: dataframe, list of atoms, start_radius, end_radius, and step_size\n",
    "# if you only want a single radius, put the same value for start_radius and end_radius (keep step_size > 0)\n",
    "vbur_list = [\"C1\", \"C2\"]\n",
    "df = gp.get_vbur_scan(df, vbur_list, 2, 2, 0.5)\n",
    "\n",
    "# ---------------Sterimol morfeus------------------\n",
    "# uses morfeus to calculate Sterimol L, B1, and B5 values\n",
    "# NOTE: this is much faster than the corresponding DBSTEP function (recommendation: use as default/if you don't need Sterimol2Vec)\n",
    "sterimol_list_of_lists = [[\"C1\", \"C2\"]]\n",
    "df = gp.get_sterimol_morfeus(df, sterimol_list_of_lists)\n",
    "\n",
    "# ---------------Buried Sterimol-------------------\n",
    "# uses morfeus to calculate Sterimol L, B1, and B5 values within a given sphere of radius r_buried\n",
    "# atoms outside the sphere + 0.5 vdW radius are deleted and the Sterimol vectors are calculated\n",
    "# for more information: https://kjelljorner.github.io/morfeus/sterimol.html\n",
    "# inputs: dataframe, list of atom pairs, r_buried\n",
    "# sterimol_list_of_lists = [[\"C1\", \"C2\"]]\n",
    "# df = gp.get_buried_sterimol(df, sterimol_list_of_lists, 5.5)\n",
    "\n",
    "# ---------------Sterimol DBSTEP-------------------\n",
    "# uses DBSTEP to calculate Sterimol L, B1, and B5 values\n",
    "# default grid point spacing (0.05 Angstrom) is used (can use custom spacing or vdw radii in the get_properties_functions script)\n",
    "# more info here: https://github.com/patonlab/DBSTEP\n",
    "# NOTE: this takes longer than the morfeus function (recommendation: only use this if you need Sterimol2Vec)\n",
    "# sterimol_list_of_lists = [[\"N1\", \"C1\"], [\"N1\", \"C5\"]]\n",
    "# df = gp.get_sterimol_dbstep(df, sterimol_list_of_lists)\n",
    "\n",
    "# ---------------Sterimol2Vec----------------------\n",
    "# uses DBSTEP to calculate Sterimol Bmin and Bmax values at intervals from 0 to end_radius, with a given step_size\n",
    "# default grid point spacing (0.05 Angstrom) is used (can use custom spacing or vdw radii in the get_properties_functions script)\n",
    "# more info here: https://github.com/patonlab/DBSTEP\n",
    "# inputs: dataframe, list of atom pairs, end_radius, and step_size\n",
    "# sterimol2vec_list_of_lists = [[\"N1\", \"C1\"], [\"N1\", \"C5\"]]\n",
    "# df = gp.get_sterimol2vec(df, sterimol2vec_list_of_lists, 1, 1.0)\n",
    "\n",
    "# ---------------Pyramidalization------------------\n",
    "# uses morfeus to calculate pyramidalization based on the 3 atoms in closest proximity to the defined atom\n",
    "# collects values based on two definitions of pyramidalization\n",
    "# details on these values can be found here: https://kjelljorner.github.io/morfeus/pyramidalization.html\n",
    "pyr_list = [\"C1\"]\n",
    "df = gp.get_pyramidalization(df, pyr_list)\n",
    "\n",
    "# ---------------Plane Angle-----------------------\n",
    "# !plane angle between 2 planes (each defined by 6 atoms)\n",
    "# planeangle_list_of_lists = [[\"N1\", \"C1\", \"C5\"], [\"C2\", \"C3\", \"C4\"]]\n",
    "# df = gp.get_planeangle(df, planeangle_list_of_lists)\n",
    "\n",
    "# --------------LP energy - custom from first cell---------------\n",
    "# lp_list = [\"N1\"]\n",
    "# df = gp.get_one_lp_energy(df, lp_list)\n",
    "\n",
    "# ---------------Time----------------------------------\n",
    "# returns the total CPU time and total Wall time (not per subjob) because we are pioneers\n",
    "# if used in summary df, will give the average (not Boltzmann average) in the Boltzmann average column\n",
    "# df = gp.get_time(df)\n",
    "\n",
    "# ---------------ChelpG----------------------------\n",
    "# ChelpG ESP charge\n",
    "# requires the Gaussian keyword = \"pop=chelpg\" in the .com file\n",
    "# a_list = [\"C1\", \"C2\", \"C3\", \"C4\", \"C5\", \"N1\"]\n",
    "# df = gp.get_chelpg(df, a_list)\n",
    "\n",
    "# ---------------Hirshfeld-------------------------\n",
    "# Hirshfeld charge, CM5 charge, Hirshfeld atom dipole\n",
    "# requires the Gaussian keyword = \"pop=hirshfeld\" in the .com file\n",
    "# a_list = [\"C1\", \"C2\", \"C3\", \"C4\", \"C5\", \"N1\"]\n",
    "# df = gp.get_hirshfeld(df, a_list)\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Save collected properties to Excel and pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the pandas dataframe to a xlsx file\n",
    "with pd.ExcelWriter(prefix + \"_extracted_properties.xlsx\") as writer:\n",
    "    df.to_excel(writer)\n",
    "# save the pandas dataframe to a pickle file\n",
    "df.to_pickle(prefix + \"_extracted_properties.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Post-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for numerically named compounds, prefix is any text common to all BEFORE the number and suffix is common to all AFTER the number\n",
    "# this is a template for our files that are all named \"AcXXX_clust-X.log\" or \"AcXXX_conf-X.log\"\n",
    "prefix = \"pyrz\"\n",
    "suffix = \"_\"\n",
    "\n",
    "# columns that provide atom mapping information are dropped, not need if these columns contain cells that cannot be convert to float\n",
    "# e.g. atom_columns_to_drop = [\"C3\", \"C4\", \"C5\", \"N1\", \"C1\", \"C2\"]\n",
    "atom_columns_to_drop = []\n",
    "\n",
    "# title of the column for the energy you want to use for boltzmann averaging and lowest E conformer determination\n",
    "energy_col_header = \"G(T)_spc(Hartree)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option to import an Excel sheet if you're using properties or energies collected outside of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If you would like to use post-processing functionality (i.e. Boltzmann averaging, lowest E conformers, etc.) you can read in a dataframe with properties (e.g. QikProp properties) or energies (e.g. if you don't/can't run linked jobs) collected outside of this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\n",
    "    prefix + \"_extracted_properties.xlsx\",\n",
    "    \"Sheet1\",\n",
    "    index_col=0,\n",
    "    header=0,\n",
    "    engine=\"openpyxl\",\n",
    ")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Generating a list of compounds that have conformational ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ONLY RUN THE AUTOMATED OR THE MANUAL CELL, NOT BOTH**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AUTOMATED:** if your compounds are named consistenly, this section generates your compound list based on the similar naming structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_list = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    log_file = row[\"log_name\"]  # read file name from df\n",
    "    prefix_and_compound = log_file.split(\n",
    "        str(suffix)\n",
    "    )  # splits to get \"AcXXX\" (entry O) (and we don't use the \"clust-X\" (entry 1))\n",
    "    compound = prefix_and_compound[0].split(\n",
    "        str(prefix)\n",
    "    )  # splits again to get \"XXX\" (entry 1) (and we don't use the empty string \"\" (entry 0))\n",
    "    compound_list.append(compound[1])\n",
    "\n",
    "compound_list = list(\n",
    "    set(compound_list)\n",
    ")  # removes duplicate stuctures that result from having conformers of each\n",
    "compound_list.sort(\n",
    "    key=lambda x: int(re.search(r\"\\d+\", x).group())\n",
    ")  # reorders numerically (not sure if it reorders alphabetically)\n",
    "print(compound_list)\n",
    "\n",
    "# this should generate a list that looks like this: ['24', '27', '34', '48']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Post-processing to get properties for each compound\n",
    "\n",
    "##### changes made in 8/30/2024 <br> 1. avoid divide by zero error in the Boltzmann averaging, the original code had the if block order reversed, which caused the error. <br> 2. data cleaning by remove columns contain cell that cannot be converted to float. <br> 3. concat all data into row before concat them into the final dataframe. The originl modify individual cells which result in fragmented and raise performance warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_master = pd.DataFrame(columns=[])\n",
    "properties_df_master = pd.DataFrame(columns=[])\n",
    "\n",
    "for compound in compound_list:\n",
    "    # defines the common start to all files using the input above\n",
    "    substring = str(prefix) + str(compound) + str(suffix)\n",
    "\n",
    "    # makes a data frame for one compound at a time for post-processing\n",
    "    valuesdf = df[df[\"log_name\"].str.startswith(substring)]\n",
    "    valuesdf = valuesdf.drop(columns=atom_columns_to_drop)\n",
    "    valuesdf = valuesdf.reset_index(\n",
    "        drop=True\n",
    "    )  # you must re-index otherwise the 2nd, 3rd, etc. compounds fail\n",
    "\n",
    "    # filter column that are characters, we will attempt to convert them to numeric numbers, if fail, we will drop them\n",
    "    for column in valuesdf:\n",
    "        try:\n",
    "            # exclude column \"log_name\"\n",
    "            if column == \"log_name\":\n",
    "                continue\n",
    "            valuesdf[column] = pd.to_numeric(valuesdf[column])\n",
    "        except:\n",
    "            # print(f\"Column {column} contains non-numeric values\")\n",
    "            valuesdf = valuesdf.drop(columns=column)\n",
    "            valuesdf = valuesdf.reset_index(\n",
    "                drop=True\n",
    "            )  # reset the index after dropping columns\n",
    "\n",
    "    # define columns that won't be included in summary properties or are treated differently because they don't make sense to Boltzmann average\n",
    "    non_boltz_columns = [\n",
    "        \"G(Hartree)\",\n",
    "        \"∆G(Hartree)\",\n",
    "        \"∆G(kcal/mol)\",\n",
    "        \"e^(-∆G/RT)\",\n",
    "        \"Mole Fraction\",\n",
    "    ]  # don't boltzman average columns containing these strings in the column label\n",
    "    reg_avg_columns = [\n",
    "        \"CPU_time_total(hours)\",\n",
    "        \"Wall_time_total(hours)\",\n",
    "    ]  # don't boltzmann average these either, we average them in case that is helpful\n",
    "    gv_extra_columns = [\n",
    "        \"G(T)_spc(Hartree)\",\n",
    "    ]\n",
    "    gv_extra_columns.remove(str(energy_col_header))\n",
    "\n",
    "    # calculate the summary properties based on all conformers (Boltzmann Average, Minimum, Maximum, Boltzmann Weighted Std)\n",
    "    valuesdf[\"∆G(Hartree)\"] = (\n",
    "        valuesdf[energy_col_header] - valuesdf[energy_col_header].min()\n",
    "    )\n",
    "    valuesdf[\"∆G(kcal/mol)\"] = valuesdf[\"∆G(Hartree)\"] * 627.5\n",
    "    valuesdf[\"e^(-∆G/RT)\"] = np.exp(\n",
    "        (valuesdf[\"∆G(kcal/mol)\"] * -1000) / (1.987204 * 298.15)\n",
    "    )  # R is in cal/(K*mol)\n",
    "    valuesdf[\"Mole Fraction\"] = valuesdf[\"e^(-∆G/RT)\"] / valuesdf[\"e^(-∆G/RT)\"].sum()\n",
    "    values_boltz_row = []\n",
    "    values_min_row = []\n",
    "    values_max_row = []\n",
    "    values_boltz_stdev_row = []\n",
    "    values_range_row = []\n",
    "    values_exclude_columns = []\n",
    "\n",
    "    for column in valuesdf:\n",
    "        if \"log_name\" in column:\n",
    "            values_boltz_row.append(\"Boltzmann Averages\")\n",
    "            values_min_row.append(\"Ensemble Minimum\")\n",
    "            values_max_row.append(\"Ensemble Maximum\")\n",
    "            values_boltz_stdev_row.append(\"Boltzmann Standard Deviation\")\n",
    "            values_range_row.append(\"Ensemble Range\")\n",
    "            values_exclude_columns.append(column)  # used later to build final dataframe\n",
    "        elif any(phrase in column for phrase in non_boltz_columns) or any(\n",
    "            phrase in column for phrase in gv_extra_columns\n",
    "        ):\n",
    "            values_boltz_row.append(\"\")\n",
    "            values_min_row.append(\"\")\n",
    "            values_max_row.append(\"\")\n",
    "            values_boltz_stdev_row.append(\"\")\n",
    "            values_range_row.append(\"\")\n",
    "        elif any(phrase in column for phrase in reg_avg_columns):\n",
    "            values_boltz_row.append(\n",
    "                valuesdf[column].mean()\n",
    "            )  # intended to print the average CPU/wall time in the boltz column\n",
    "            values_min_row.append(\"\")\n",
    "            values_max_row.append(\"\")\n",
    "            values_boltz_stdev_row.append(\"\")\n",
    "            values_range_row.append(\"\")\n",
    "        else:\n",
    "            valuesdf[column] = pd.to_numeric(\n",
    "                valuesdf[column]\n",
    "            )  # to hopefully solve the error that sometimes occurs where the float(Mole Fraction) cannot be mulitplied by the string(property)\n",
    "            values_boltz_row.append(\n",
    "                (valuesdf[column] * valuesdf[\"Mole Fraction\"]).sum()\n",
    "            )\n",
    "            values_min_row.append(valuesdf[column].min())\n",
    "            values_max_row.append(valuesdf[column].max())\n",
    "            values_range_row.append(valuesdf[column].max() - valuesdf[column].min())\n",
    "\n",
    "            # this section generates the weighted std deviation (weighted by mole fraction)\n",
    "            # formula: https://www.statology.org/weighted-standard-deviation-excel/\n",
    "\n",
    "            boltz = (valuesdf[column] * valuesdf[\"Mole Fraction\"]).sum()  # number\n",
    "            delta_values_sq = []\n",
    "\n",
    "            # makes a list of the \"deviation\" for each conformer\n",
    "            for index, row in valuesdf.iterrows():\n",
    "                value = row[column]\n",
    "                delta_value_sq = (value - boltz) ** 2\n",
    "                delta_values_sq.append(delta_value_sq)\n",
    "\n",
    "            # w is list of weights (i.e. mole fractions)\n",
    "            w = list(valuesdf[\"Mole Fraction\"])\n",
    "            # !swap the order here to avoid division by zero error\n",
    "            if (\n",
    "                len(w) == 1\n",
    "            ):  # if there is only one conformer in the ensemble, set the weighted standard deviation to 0\n",
    "                wstdev = 0\n",
    "            # np.average(delta_values_sq, weights=w) generates sum of each (delta_value_sq * mole fraction)\n",
    "            else:\n",
    "                wstdev = np.sqrt(\n",
    "                    (np.average(delta_values_sq, weights=w))\n",
    "                    / (((len(w) - 1) / len(w)) * np.sum(w))\n",
    "                )\n",
    "            values_boltz_stdev_row.append(wstdev)\n",
    "\n",
    "    valuesdf.loc[len(valuesdf)] = values_boltz_row\n",
    "    valuesdf.loc[len(valuesdf)] = values_boltz_stdev_row\n",
    "    valuesdf.loc[len(valuesdf)] = values_min_row\n",
    "    valuesdf.loc[len(valuesdf)] = values_max_row\n",
    "    valuesdf.loc[len(valuesdf)] = values_range_row\n",
    "\n",
    "    # final output format is built here:\n",
    "    explicit_order_front_columns = [\n",
    "        \"log_name\",\n",
    "        energy_col_header,\n",
    "        \"∆G(Hartree)\",\n",
    "        \"∆G(kcal/mol)\",\n",
    "        \"e^(-∆G/RT)\",\n",
    "        \"Mole Fraction\",\n",
    "    ]\n",
    "\n",
    "    # reorders the dataframe using front columns defined above\n",
    "    valuesdf = valuesdf[\n",
    "        explicit_order_front_columns\n",
    "        + [\n",
    "            col\n",
    "            for col in valuesdf.columns\n",
    "            if col not in explicit_order_front_columns\n",
    "            and col not in values_exclude_columns\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # determine the index of the lowest energy conformer\n",
    "    low_e_index = valuesdf[valuesdf[\"∆G(Hartree)\"] == 0].index.tolist()\n",
    "    # copy the row to a new_row with the name of the log changed to Lowest E Conformer\n",
    "    new_row = pd.DataFrame(valuesdf.loc[low_e_index[0]]).T\n",
    "    new_row[\"log_name\"] = \"Lowest E Conformer\"\n",
    "\n",
    "    valuesdf = pd.concat([valuesdf, new_row], ignore_index=True, axis=0)\n",
    "\n",
    "    # ------------------------------EDIT THIS SECTION IF YOU WANT A SPECIFIC CONFORMER----------------------------------\n",
    "    # if you want all properties for a conformer with a particular property (i.e. all properties for the Vbur_min conformer)\n",
    "    # this template can be adjusted for min/max/etc.\n",
    "\n",
    "    # find the index for the min or max column:\n",
    "    ensemble_min_index = valuesdf[\n",
    "        valuesdf[\"log_name\"] == \"Ensemble Minimum\"\n",
    "    ].index.tolist()\n",
    "\n",
    "    # find the min or max value of the property (based on index above)\n",
    "    # saves the value in a list (min_value) with one entry (this is why we call min_value[0])\n",
    "    min_value = valuesdf.loc[ensemble_min_index, \"%Vbur_C1_2.0Å\"].tolist()\n",
    "    vbur_min_index = valuesdf[valuesdf[\"%Vbur_C1_2.0Å\"] == min_value[0]].index.tolist()\n",
    "\n",
    "    # copy the row to a new_row with the name of the log changed to Property_min_conformer\n",
    "    new_row = pd.DataFrame(valuesdf.loc[vbur_min_index[0]]).T\n",
    "    new_row[\"log_name\"] = \"%Vbur_C1_2.0Å_min_Conformer\"\n",
    "\n",
    "    valuesdf = pd.concat([valuesdf, new_row], ignore_index=True, axis=0)\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # !here we define a list of properties we only want the minimal value for\n",
    "    min_property_list = [\n",
    "        \"E_spc (Hartree)\",\n",
    "        \"H_spc(Hartree)\",\n",
    "        \"T\",\n",
    "        \"T*S\",\n",
    "        \"T*qh_S\",\n",
    "        \"ZPE(Hartree)\",\n",
    "        \"qh_G(T)_spc(Hartree)\",\n",
    "        \"G(T)_spc(Hartree)\",\n",
    "    ]\n",
    "    # extract the \"Lowest E Conformer\" row out of the dataframe\n",
    "    Low_E_Conformer_row = pd.DataFrame(\n",
    "        valuesdf.loc[valuesdf[\"log_name\"] == \"Lowest E Conformer\"]\n",
    "    )\n",
    "    # display(valuesdf) # debug display for finding the row index\n",
    "    # display(Low_E_Conformer_row)\n",
    "\n",
    "    # appends the frame to the master output\n",
    "    all_df_master = pd.concat([all_df_master, valuesdf])\n",
    "\n",
    "    # drop all the individual conformers\n",
    "    dropindex = valuesdf[valuesdf[\"log_name\"].str.startswith(substring)].index\n",
    "    valuesdf = valuesdf.drop(dropindex)\n",
    "    valuesdf = valuesdf.reset_index(drop=True)\n",
    "\n",
    "    # drop the columns created to determine the mole fraction and some that\n",
    "    valuesdf = valuesdf.drop(columns=explicit_order_front_columns)\n",
    "    try:\n",
    "        valuesdf = valuesdf.drop(columns=gv_extra_columns)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        valuesdf = valuesdf.drop(columns=reg_avg_columns)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # ---------------------THIS MAY NEED TO CHANGE DEPENDING ON HOW YOU LABEL YOUR COMPOUNDS------------------------------\n",
    "    compound_name = prefix + str(compound)\n",
    "    # --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    properties_df = pd.DataFrame({\"Compound_Name\": [compound_name]})\n",
    "\n",
    "    # builds a dataframe (for each compound) by adding summary properties as new columns\n",
    "    for column in valuesdf:\n",
    "        # print(column)\n",
    "        # the indexes need to match the values dataframe - display it to double check if you need to make changes\n",
    "        # (uncomment the display(valuesdf) in row 124 of this cell)\n",
    "\n",
    "        # create a list of headers for the properties_df\n",
    "        # if you're collecting properties for a specific conformer, edit the header to reflect that, it should match the order in the valuesdf log_name column\n",
    "        if column in min_property_list:\n",
    "            # ! if we are working with a property that we only want the minimum value for, we only need one header\n",
    "            headers = [\n",
    "                f\"{column}\",\n",
    "            ]\n",
    "            # use data from the Low_E_Conformer_row\n",
    "            row_dataframe = pd.DataFrame(\n",
    "                [Low_E_Conformer_row[column].values], columns=headers\n",
    "            )\n",
    "        else:\n",
    "            headers = [\n",
    "                f\"{column}_Boltz\",\n",
    "                f\"{column}_Boltz_stdev\",\n",
    "                f\"{column}_min\",\n",
    "                f\"{column}_max\",\n",
    "                f\"{column}_range\",\n",
    "                f\"{column}_low_E\",\n",
    "                f\"{column}_Vbur_min\",\n",
    "            ]\n",
    "            row_dataframe = pd.DataFrame([valuesdf[column].values], columns=headers)\n",
    "        # Extract values for the current column from valuesdf and create a DataFrame\n",
    "        # Display the DataFrame for verification\n",
    "        # display(row_dataframe)\n",
    "        # Concatenate the new DataFrame to the properties_df along the columns (axis=1)\n",
    "        properties_df = pd.concat([properties_df, row_dataframe], axis=1)\n",
    "\n",
    "    # concatenates the individual acid properties df into the master properties df\n",
    "    properties_df_master = pd.concat([properties_df_master, properties_df], axis=0)\n",
    "\n",
    "# Reset the index of the master DataFrames\n",
    "all_df_master = all_df_master.reset_index(drop=True)\n",
    "properties_df_master = properties_df_master.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Export the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print in tabulated version\n",
    "print(tabulate(properties_df_master, headers=\"keys\", tablefmt=\"pretty\"))\n",
    "print(tabulate(all_df_master, headers=\"keys\", tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grep the first & last Compound_Name\n",
    "first_compound = str(properties_df_master[\"Compound_Name\"].iloc[0])\n",
    "last_compound = str(properties_df_master[\"Compound_Name\"].iloc[-1])\n",
    "\n",
    "# Define the filename for the Excel file\n",
    "filename = (\n",
    "    prefix\n",
    "    + \"_properties_postprocessed_\"\n",
    "    + \"for_\"\n",
    "    + first_compound\n",
    "    + \"_to_\"\n",
    "    + last_compound\n",
    "    + \".xlsx\"\n",
    ")\n",
    "\n",
    "# export to excel\n",
    "with pd.ExcelWriter(filename, engine=\"xlsxwriter\") as writer:\n",
    "    all_df_master.to_excel(writer, sheet_name=\"All_Conformer_Properties\", index=False)\n",
    "    # automatically adjusts the width of the columns\n",
    "    for column in all_df_master.columns:\n",
    "        column_width = max(\n",
    "            all_df_master[column].astype(str).map(len).max(), len(column)\n",
    "        )\n",
    "        col_idx = all_df_master.columns.get_loc(column)\n",
    "        writer.sheets[\"All_Conformer_Properties\"].set_column(\n",
    "            col_idx, col_idx, column_width\n",
    "        )\n",
    "    properties_df_master.to_excel(writer, sheet_name=\"Summary_Properties\", index=False)\n",
    "    # automatically adjusts the width of the columns\n",
    "    for column in properties_df_master.columns:\n",
    "        column_width = max(\n",
    "            properties_df_master[column].astype(str).map(len).max(), len(column)\n",
    "        )\n",
    "        col_idx = properties_df_master.columns.get_loc(column)\n",
    "        writer.sheets[\"Summary_Properties\"].set_column(col_idx, col_idx, column_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define filenames for the pickle files\n",
    "pkl_filename_all = (\n",
    "    prefix\n",
    "    + \"_properties_postprocessed\"\n",
    "    + \"_all_conformer_properties\"\n",
    "    + \"_for_\"\n",
    "    + prefix\n",
    "    + \".pkl\"\n",
    ")\n",
    "pkl_filename_summary = (\n",
    "    prefix\n",
    "    + \"_properties_postprocessed\"\n",
    "    + \"_summary_properties\"\n",
    "    + \"_for_\"\n",
    "    + prefix\n",
    "    + \".pkl\"\n",
    ")\n",
    "\n",
    "# Save to pickle\n",
    "all_df_master.to_pickle(pkl_filename_all)\n",
    "properties_df_master.to_pickle(pkl_filename_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

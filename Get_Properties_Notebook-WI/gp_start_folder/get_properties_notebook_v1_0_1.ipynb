{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ace26e4",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6f66f2",
   "metadata": {},
   "source": [
    "Brittany C. Haas and Melissa A. Hardy's jupyter notebook for automated collection of molecular descriptors and post-processing (i.e., Boltzmann average, min/max values, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21f83e3",
   "metadata": {},
   "source": [
    "**NOTE: Make sure to use the get_properties_environment file to set your conda environment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fca42e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T15:27:30.608450Z",
     "start_time": "2022-04-08T15:27:12.248762Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os,re,sys,pickle,datetime,time,random,itertools,glob\n",
    "from itertools import permutations\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=sys.maxsize) #print out full arrays\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "import xlsxwriter\n",
    "\n",
    "import math\n",
    "randomstate = 42\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "import goodvibes.GoodVibes as gv\n",
    "import goodvibes.thermo as thermo\n",
    "import goodvibes.io as io\n",
    "import goodvibes.pes as pes\n",
    "from morfeus import ConeAngle\n",
    "from morfeus import Sterimol\n",
    "import get_properties_functions as gp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b467cdad",
   "metadata": {},
   "source": [
    "# Atom Inputs Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433f0c25",
   "metadata": {},
   "source": [
    "Portions of this section were adapted from code written Jordan P. Liles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc9b0c7",
   "metadata": {},
   "source": [
    "## Generate dataframe with atom numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae2c643",
   "metadata": {},
   "source": [
    "### Use command line to prepare files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d16f0",
   "metadata": {},
   "source": [
    "To create files: navigate to folder that contains all the log files you wish to analyze.\n",
    "\n",
    "    module load openbabel\n",
    "    obabel *.log -osdf -m  \n",
    "    ls *.log > log_ids.txt\n",
    "    cat *.sdf >> molecules.sdf\n",
    "\n",
    "You will use the log_ids.txt and molecules.sdf files in the rest of 2.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510730a1",
   "metadata": {},
   "source": [
    "### Define SMARTS substructure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d590665",
   "metadata": {},
   "source": [
    "Recommended to draw the common substructure (with general atoms) in Chemdraw and copy as SMILES (this will generate a SMARTS string)\n",
    "\n",
    "More information about SMARTS and available characters here: https://www.daylight.com/dayhtml/doc/theory/theory.smarts.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d355af9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T15:41:31.570285Z",
     "start_time": "2022-04-08T15:41:31.508039Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "#this is the common smarts substructure for the molecules you will analyze\n",
    "#you have to explicitly draw hydrogens into the SMARTS structure if you want to collect properties for hydrogen atoms\n",
    "substructure = Chem.MolFromSmarts('[*]C(O[H])=O')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c57ae30",
   "metadata": {},
   "source": [
    "### Generate preliminary dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b46f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T15:41:53.816681Z",
     "start_time": "2022-04-08T15:41:53.647653Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#generate a list of molecules using RDkit\n",
    "all_compounds = Chem.SDMolSupplier('molecules.sdf', removeHs=False) \n",
    "#molecules.sdf is generated with the instructions above\n",
    "#it is a single sdf that contains the structures/atom numbers etc. for every molecule you will analyze\n",
    "\n",
    "#uses RDKit to search for the substructure in each compound you will analyze\n",
    "atoms = []\n",
    "for molecule in all_compounds:\n",
    "    if molecule is not None:\n",
    "        submatch = molecule.GetSubstructMatches(substructure) #find substructure\n",
    "        matchlist = list([item for sublist in submatch for item in sublist]) #list of zero-indexed atom numbers\n",
    "        match_idx = [x+1 for x in matchlist] #this line changes from 0-indexed to 1-indexed (for Gaussian)\n",
    "        atoms.append(match_idx) #append 1-indexed list to atoms (a list of lists)\n",
    "        \n",
    "#this loop extracts log names from log_ids and splits them to the desired format\n",
    "filenames = open(\"log_ids.txt\", \"r\") #generate this with instruction above\n",
    "#it is a text file that contains the file name for every molecule you will analyze\n",
    "list_of_filenames = [(line.strip()).split() for line in filenames] #list of the file names (each of which includes all conformers)\n",
    "list_of_files = []\n",
    "for filename in list_of_filenames:\n",
    "    file = filename[0].split(\".\")\n",
    "    list_of_files.append(file[0])\n",
    "filenames.close()\n",
    "\n",
    "#put the atom numbers for the substructure for each log file into a dataframe\n",
    "prelim_df = pd.DataFrame(atoms) \n",
    "index=list_of_files\n",
    "prelim_df.insert(0,column='log_name',value=list_of_files)\n",
    "display(prelim_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f04d55f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Define column headers using GaussView"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5e92e3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using the preliminary dataframe displayed above, open one of your files and check the atom numbers. \n",
    "\n",
    "Assign labels to each column using the cell below. You will call these column headers when you select your properties. \n",
    "\n",
    "**User input required:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781af96b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T15:48:32.406986Z",
     "start_time": "2022-04-08T15:48:32.388537Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "atom_labels = {'log_name': 'log_name',\n",
    "                0: 'C4',\n",
    "                1: 'C1', \n",
    "                2: 'O3',\n",
    "                3: 'H5',\n",
    "                4: 'O2'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89b1b7e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Generate labeled dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967d1c9d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**NOTE: it is very important you assign these correctly otherwise the properties you collect will be for the wrong atoms and not produce meaningful correlations.** \n",
    "\n",
    "We recommend checking the numbering/headers for at least two different compounds. \n",
    "\n",
    "Numbering for different conformers of the same compounds will likely be the same (but may not be for some symmetrical groups)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d8730a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T15:52:56.563871Z",
     "start_time": "2022-04-08T15:52:56.511805Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#rename columns using the user input above\n",
    "atom_map_df = prelim_df.rename(columns=atom_labels)\n",
    "display(atom_map_df)\n",
    "\n",
    "#you can use this to clean up the table if you have more atoms in your substructure than you want to collect descriptors for\n",
    "#atom_map_df = atom_map_df.drop(columns= ['C4', 'C1']) \n",
    "#display(atom_map_df.head())\n",
    "\n",
    "df = atom_map_df #df is what properties will be appended to, this creates a copy so that you have the original preserved "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f175ea46",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Save atom map to Excel (if desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d63b886",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T20:41:27.350748Z",
     "start_time": "2022-03-24T20:41:27.287874Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('atom_map_Ac2_Ac6.xlsx')\n",
    "atom_map_df.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4ee4fb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Import a manually-generated atom mapping dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b0b000",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If you need to manually generate the atom mapping dataframe, check out the atom_map_sample.xlsx to make sure you have the desired format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f208cacd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T15:52:44.033080Z",
     "start_time": "2022-04-08T15:52:43.771243Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "atom_map_df = pd.read_excel('atom_map_sample.xlsx','Sheet1',index_col=0,header=0,engine='openpyxl')\n",
    "display(atom_map_df.head())\n",
    "df = atom_map_df #df is what properties will be appended to, this creates a copy so that you have the original preserved "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34481000",
   "metadata": {},
   "source": [
    "# Define Properties to Collect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eb120b",
   "metadata": {},
   "source": [
    "## Available property functions and how to call them: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653fef6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T21:02:33.814731Z",
     "start_time": "2022-03-29T20:57:31.564494Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this box has functions to choose from\n",
    "df = atom_map_df\n",
    "\n",
    "#---------------GoodVibes Engergies---------------\n",
    "#uses the GoodVibes 2021 Branch (Jupyter Notebook Compatible)\n",
    "#calculates the quasi harmonic corrected G(T) and single point corrected G(T) as well as other thermodynamic properties\n",
    "#inputs: dataframe, temperature\n",
    "df = gp.get_goodvibes_e(df, 298.15)\n",
    "\n",
    "#---------------Frontier Orbitals-----------------\n",
    "#E(HOMO), E(LUMO), mu(chemical potential or negative of molecular electronegativity), eta(hardness/softness), omega(electrophilicity index)\n",
    "df = gp.get_frontierorbs(df)\n",
    "\n",
    "#---------------Polarizability--------------------\n",
    "#Exact polarizability\n",
    "df = gp.get_polarizability(df)\n",
    "\n",
    "#---------------Dipole----------------------------\n",
    "#Total dipole moment magnitude in Debye\n",
    "df = gp.get_dipole(df)\n",
    "\n",
    "#---------------Volume----------------------------\n",
    "#Molar volume\n",
    "#requires the Gaussian keyword = \"volume\" in the .com file\n",
    "df = gp.get_volume(df)\n",
    "\n",
    "#---------------SASA------------------------------\n",
    "#Uses morfeus to calculat sovlent accessible surface area and the volume under the SASA\n",
    "df = gp.get_SASA(df)\n",
    "\n",
    "#---------------NBO-------------------------------\n",
    "#natural charge from NBO\n",
    "#requires the Gaussian keyword = \"pop=nbo7\" in the .com file\n",
    "nbo_list = [\"C1\", \"C2\", \"C3\", \"C4\", \"C5\", \"N1\"]\n",
    "df = gp.get_nbo(df, nbo_list)\n",
    "\n",
    "#---------------NMR-------------------------------\n",
    "#isotropic NMR shift\n",
    "#requires the Gaussian keyword = \"nmr=giao\" in the .com file\n",
    "nmr_list = [\"C1\", \"C2\", \"C3\", \"C4\", \"C5\", \"N1\"]\n",
    "df = gp.get_nmr(df, nmr_list)\n",
    "\n",
    "#---------------Distance--------------------------\n",
    "#distance between 2 atoms\n",
    "dist_list_of_lists = [[\"N1\", \"C1\"], [\"N1\", \"C5\"]]\n",
    "df = gp.get_distance(df, dist_list_of_lists)\n",
    "\n",
    "#---------------Angle-----------------------------\n",
    "#angle between 3 atoms\n",
    "angle_list_of_lists = [[\"C5\", \"N1\",\"C1\"]]\n",
    "df = gp.get_angles(df, angle_list_of_lists)\n",
    "\n",
    "#---------------Dihedral--------------------------\n",
    "#dihedral angle between 4 atoms\n",
    "dihedral_list_of_lists = [[\"C4\", \"C5\", \"N1\", \"C1\"]]\n",
    "df = gp.get_dihedral(df, dihedral_list_of_lists)\n",
    "\n",
    "#---------------Vbur Scan-------------------------\n",
    "#uses morfeus to calculate the buried volume at a series of radii (including hydrogens)\n",
    "#inputs: dataframe, list of atoms, start_radius, end_radius, and step_size\n",
    "#if you only want a single radius, put the same value for start_radius and end_radius (keep step_size > 0)\n",
    "vbur_list = [\"C1\", \"C2\", \"C3\", \"C4\", \"C5\", \"N1\"]\n",
    "df = gp.get_vbur_scan(df, vbur_list, 2, 4, 0.5)\n",
    "\n",
    "#---------------Sterimol morfeus------------------\n",
    "#uses morfeus to calculate Sterimol L, B1, and B5 values\n",
    "#NOTE: this is much faster than the corresponding DBSTEP function (recommendation: use as default/if you don't need Sterimol2Vec)\n",
    "sterimol_list_of_lists = [[\"N1\", \"C1\"], [\"N1\", \"C5\"]]\n",
    "df = gp.get_sterimol_morfeus(df, sterimol_list_of_lists)\n",
    "\n",
    "#---------------Buried Sterimol-------------------\n",
    "#uses morfeus to calculate Sterimol L, B1, and B5 values within a given sphere of radius r_buried\n",
    "#atoms outside the sphere + 0.5 vdW radius are deleted and the Sterimol vectors are calculated\n",
    "#for more information: https://kjelljorner.github.io/morfeus/sterimol.html\n",
    "#inputs: dataframe, list of atom pairs, r_buried\n",
    "sterimol_list_of_lists = [[\"N1\", \"C1\"], [\"N1\", \"C5\"]]\n",
    "df = gp.get_buried_sterimol(df, sterimol_list_of_lists, 5.5)\n",
    "\n",
    "#---------------Sterimol DBSTEP-------------------\n",
    "#uses DBSTEP to calculate Sterimol L, B1, and B5 values\n",
    "#default grid point spacing (0.05 Angstrom) is used (can use custom spacing or vdw radii in the get_properties_functions script)\n",
    "#more info here: https://github.com/patonlab/DBSTEP\n",
    "#NOTE: this takes longer than the morfeus function (recommendation: only use this if you need Sterimol2Vec)\n",
    "sterimol_list_of_lists = [[\"N1\", \"C1\"]]\n",
    "df = gp.get_sterimol_dbstep(df, sterimol_list_of_lists)\n",
    "\n",
    "#---------------Sterimol2Vec----------------------\n",
    "#uses DBSTEP to calculate Sterimol Bmin and Bmax values at intervals from 0 to end_radius, with a given step_size\n",
    "#default grid point spacing (0.05 Angstrom) is used (can use custom spacing or vdw radii in the get_properties_functions script)\n",
    "#more info here: https://github.com/patonlab/DBSTEP\n",
    "#inputs: dataframe, list of atom pairs, end_radius, and step_size\n",
    "sterimol2vec_list_of_lists = [[\"N1\", \"C5\"], [\"N1\", \"C1\"]]\n",
    "df = gp.get_sterimol2vec(df, sterimol2vec_list_of_lists, 1, 1.0)\n",
    "\n",
    "#---------------Pyramidalization------------------\n",
    "#uses morfeus to calculate pyramidalization based on the 3 atoms in closest proximity to the defined atom\n",
    "#collects values based on two definitions of pyramidalization\n",
    "#details on these values can be found here: https://kjelljorner.github.io/morfeus/pyramidalization.html\n",
    "pyr_list = [\"C1\", \"C2\", \"C3\", \"C4\", \"C5\", \"N1\"]\n",
    "df = gp.get_pyramidalization(df, pyr_list)\n",
    "\n",
    "#---------------Plane Angle-----------------------\n",
    "#plane angle between 2 planes (each defined by 3 atoms)\n",
    "planeangle_list_of_lists = [[\"N1\", \"C1\", \"C5\"], [\"C2\", \"C3\", \"C4\"]]\n",
    "df = gp.get_planeangle(df, planeangle_list_of_lists)\n",
    "\n",
    "#--------------LP energy - custom from first cell---------------\n",
    "lp_list = [\"N1\"]\n",
    "df = gp.get_one_lp_energy(df, lp_list)\n",
    "\n",
    "#---------------Time----------------------------------\n",
    "#returns the total CPU time and total Wall time (not per subjob) because we are pioneers\n",
    "#if used in summary df, will give the average (not Boltzmann average) in the Boltzmann average column\n",
    "df = gp.get_time(df)\n",
    "\n",
    "#---------------ChelpG----------------------------\n",
    "#ChelpG ESP charge \n",
    "#requires the Gaussian keyword = \"pop=chelpg\" in the .com file\n",
    "a_list = ['C1']\n",
    "df = gp.get_chelpg(df, a_list)\n",
    "\n",
    "#---------------Hirshfeld-------------------------\n",
    "#Hirshfeld charge, CM5 charge, Hirshfeld atom dipole\n",
    "#requires the Gaussian keyword = \"pop=hirshfeld\" in the .com file\n",
    "a_list = ['C1']\n",
    "df = gp.get_hirshfeld(df, a_list)\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96c7c7c",
   "metadata": {},
   "source": [
    "## Copy and modify available property functions above to customize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa3d653",
   "metadata": {},
   "source": [
    "We recommend copying the entire cell above. You will need to change the atom number lists to match your desired column headers and delete (or comment out) any properites you don't want to collect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c446873",
   "metadata": {},
   "source": [
    "## Other available property functions that are less common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd29d5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T17:02:30.125132Z",
     "start_time": "2022-04-08T17:02:24.483062Z"
    },
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = atom_map_df\n",
    "#---------------Time----------------------------------\n",
    "#returns the total CPU time and total Wall time (not per subjob) because we are pioneers\n",
    "#if used in summary df, will give the average (not Boltzmann average) in the Boltzmann average column\n",
    "df = gp.get_time(df)\n",
    "\n",
    "#---------------ChelpG----------------------------\n",
    "#ChelpG ESP charge \n",
    "#requires the Gaussian keyword = \"pop=chelpg\" in the .com file\n",
    "a_list = ['C1']\n",
    "df = gp.get_chelpg(df, a_list) \n",
    "\n",
    "#---------------Hirshfeld-------------------------\n",
    "#Hirshfeld charge, CM5 charge, Hirshfeld atom dipole\n",
    "#requires the Gaussian keyword = \"pop=hirshfeld\" in the .com file\n",
    "a_list = ['C1']\n",
    "df = gp.get_hirshfeld(df, a_list) \n",
    "\n",
    "#---------------IR--------------------------------\n",
    "#CAUTION: CANNOT ACCURATELY IDENTIFY ATOM STRETCHES IN MOST CASES (strugges if there is more than one stretch in the defined range)\n",
    "#IR frequencies and intensities in a specific range (for specific atoms)\n",
    "#requires the Gaussian keyword = \"freq=noraman\" in the .com file\n",
    "#inputs: dataframe, atom1, atom2, frequency_min, frequency_max, intensity_min, intensity_max, threshold\n",
    "#if you want to collect multiple IR frequencies, you will need to copy/paste this function for each stretch\n",
    "#we recommend a threshold of 0.0 (may have to adjust)\n",
    "df = gp.get_IR(df, \"C1\", \"O2\", 1700, 1900, 100, 800, 0.0)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2551892",
   "metadata": {},
   "source": [
    "## Save collected properties to Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0adc17",
   "metadata": {},
   "source": [
    "Helpful to save here in case the Notebook crashes or if you want to add more properties before post-processsing. Can be read in at 5.1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b57cd1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T22:07:38.276346Z",
     "start_time": "2022-03-22T22:07:38.170016Z"
    }
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('properties.xlsx')\n",
    "df.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ba3fdc",
   "metadata": {},
   "source": [
    "# Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3afca96",
   "metadata": {},
   "source": [
    "## User input for data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9caca8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T16:53:49.327612Z",
     "start_time": "2022-04-08T16:53:49.310686Z"
    }
   },
   "outputs": [],
   "source": [
    "#for numerically named compounds, prefix is any text common to all BEFORE the number and suffix is common to all AFTER the number\n",
    "#this is a template for our files that are all named \"AcXXX_clust-X.log\" or \"AcXXX_conf-X.log\"\n",
    "prefix = \"Ac\" \n",
    "suffix = \"_\"\n",
    "\n",
    "#columns that provide atom mapping information are dropped\n",
    "atom_columns_to_drop = [\"C1\", \"O2\", \"O3\", \"C4\", \"H5\"]\n",
    "\n",
    "#title of the column for the energy you want to use for boltzmann averaging and lowest E conformer determination\n",
    "energy_col_header = \"G(T)_spc(Hartree)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9114d73",
   "metadata": {},
   "source": [
    "### Option to import an Excel sheet if you're using properties or energies collected outside of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7417c8e",
   "metadata": {},
   "source": [
    "If you would like to use post-processing functionality (i.e. Boltzmann averaging, lowest E conformers, etc.) you can read in a dataframe with properties (e.g. QikProp properties) or energies (e.g. if you don't/can't run linked jobs) collected outside of this notebook. \n",
    "\n",
    "Check out the dataframe_sample.xlsx to make sure you have the desired format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373233c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-18T21:41:18.131523Z",
     "start_time": "2022-03-18T21:41:17.928900Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('manual_properties_sample.xlsx','Sheet1',index_col=0,header=0,engine='openpyxl')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1762410a",
   "metadata": {},
   "source": [
    "## Generating a list of compounds that have conformational ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace92061",
   "metadata": {},
   "source": [
    "**ONLY RUN THE AUTOMATED OR THE MANUAL CELL, NOT BOTH**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcacc753",
   "metadata": {},
   "source": [
    "**AUTOMATED:** if your compounds are named consistenly, this section generates your compound list based on the similar naming structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9da438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T16:54:31.242259Z",
     "start_time": "2022-04-08T16:54:31.229294Z"
    }
   },
   "outputs": [],
   "source": [
    "#this is a template for our files that are all named \"AcXXX_clust-X.log\"\n",
    "\n",
    "compound_list = []\n",
    "    \n",
    "for index, row in df.iterrows():\n",
    "    log_file = row['log_name'] #read file name from df\n",
    "    prefix_and_compound = log_file.split(str(suffix)) #splits to get \"AcXXX\" (entry O) (and we don't use the \"clust-X\" (entry 1))\n",
    "    compound = prefix_and_compound[0].split(str(prefix)) #splits again to get \"XXX\" (entry 1) (and we don't use the empty string \"\" (entry 0))\n",
    "    compound_list.append(compound[1])\n",
    "\n",
    "compound_list = list(set(compound_list)) #removes duplicate stuctures that result from having conformers of each\n",
    "compound_list.sort() #reorders numerically (not sure if it reorders alphabetically)\n",
    "print(compound_list)\n",
    "\n",
    "#this should generate a list that looks like this: ['24', '27', '34', '48']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84881515",
   "metadata": {},
   "source": [
    "**MANUAL:** if your comment naming scheme is not consistent or you have trouble with the template above, you can manually define your compound list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a285ed19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T16:54:29.375268Z",
     "start_time": "2022-04-08T16:54:29.369283Z"
    }
   },
   "outputs": [],
   "source": [
    "compound_list = [24, 27, 34, 48]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933362f0",
   "metadata": {},
   "source": [
    "## Post-processing to get properties for each compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0726fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T17:00:13.149200Z",
     "start_time": "2022-04-08T17:00:09.163878Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_df_master = pd.DataFrame(columns=[])\n",
    "properties_df_master = pd.DataFrame(columns=[])\n",
    "\n",
    "for compound in compound_list: \n",
    "    #defines the common start to all files using the input above \n",
    "    substring = str(prefix) + str(compound) + str(suffix)\n",
    "    \n",
    "    #makes a data frame for one compound at a time for post-processing\n",
    "    valuesdf = df[df[\"log_name\"].str.startswith(substring)]\n",
    "    valuesdf = valuesdf.drop(columns = atom_columns_to_drop)\n",
    "    valuesdf = valuesdf.reset_index(drop = True)  #you must re-index otherwise the 2nd, 3rd, etc. compounds fail\n",
    "   \n",
    "    #define columns that won't be included in summary properties or are treated differently because they don't make sense to Boltzmann average\n",
    "    non_boltz_columns = [\"G(Hartree)\",\"∆G(Hartree)\",\"∆G(kcal/mol)\", \"e^(-∆G/RT)\",\"Mole Fraction\"] #don't boltzman average columns containing these strings in the column label\n",
    "    reg_avg_columns = ['CPU_time_total(hours)', 'Wall_time_total(hours)'] #don't boltzmann average these either, we average them in case that is helpful\n",
    "    gv_extra_columns = ['E_spc (Hartree)', 'H_spc(Hartree)', 'T', 'T*S', 'T*qh_S', 'ZPE(Hartree)', 'qh_G(T)_spc(Hartree)', \"G(T)_spc(Hartree)\"]\n",
    "    gv_extra_columns.remove(str(energy_col_header))\n",
    "    \n",
    "    #calculate the summary properties based on all conformers (Boltzmann Average, Minimum, Maximum, Boltzmann Weighted Std)\n",
    "    valuesdf[\"∆G(Hartree)\"] = valuesdf[energy_col_header] - valuesdf[energy_col_header].min()\n",
    "    valuesdf[\"∆G(kcal/mol)\"] = valuesdf[\"∆G(Hartree)\"] * 627.5\n",
    "    valuesdf[\"e^(-∆G/RT)\"] = np.exp((valuesdf[\"∆G(kcal/mol)\"] * -1000) / (1.987204 * 298.15)) #R is in cal/(K*mol)\n",
    "    valuesdf[\"Mole Fraction\"] = valuesdf[\"e^(-∆G/RT)\"] / valuesdf[\"e^(-∆G/RT)\"].sum()\n",
    "    values_boltz_row = []\n",
    "    values_min_row = []\n",
    "    values_max_row = []\n",
    "    values_boltz_stdev_row =[]\n",
    "    values_range_row = []\n",
    "    values_exclude_columns = []\n",
    "    \n",
    "    for column in valuesdf:\n",
    "        if \"log_name\" in column:\n",
    "            values_boltz_row.append(\"Boltzmann Averages\")\n",
    "            values_min_row.append(\"Ensemble Minimum\")\n",
    "            values_max_row.append(\"Ensemble Maximum\")\n",
    "            values_boltz_stdev_row.append(\"Boltzmann Standard Deviation\")\n",
    "            values_range_row.append(\"Ensemble Range\")\n",
    "            values_exclude_columns.append(column) #used later to build final dataframe\n",
    "        elif any(phrase in column for phrase in non_boltz_columns) or any(phrase in column for phrase in gv_extra_columns):\n",
    "            values_boltz_row.append(\"\")\n",
    "            values_min_row.append(\"\")\n",
    "            values_max_row.append(\"\")\n",
    "            values_boltz_stdev_row.append(\"\")\n",
    "            values_range_row.append(\"\")\n",
    "        elif any(phrase in column for phrase in reg_avg_columns):\n",
    "            values_boltz_row.append(valuesdf[column].mean()) #intended to print the average CPU/wall time in the boltz column\n",
    "            values_min_row.append(\"\")\n",
    "            values_max_row.append(\"\")\n",
    "            values_boltz_stdev_row.append(\"\")\n",
    "            values_range_row.append(\"\")\n",
    "        else:\n",
    "            valuesdf[column] = pd.to_numeric(valuesdf[column]) #to hopefully solve the error that sometimes occurs where the float(Mole Fraction) cannot be mulitplied by the string(property)\n",
    "            values_boltz_row.append((valuesdf[column] * valuesdf[\"Mole Fraction\"]).sum())\n",
    "            values_min_row.append(valuesdf[column].min())\n",
    "            values_max_row.append(valuesdf[column].max())\n",
    "            values_range_row.append(valuesdf[column].max() - valuesdf[column].min())\n",
    "\n",
    "            \n",
    "            # this section generates the weighted std deviation (weighted by mole fraction) \n",
    "            # formula: https://www.statology.org/weighted-standard-deviation-excel/\n",
    "    \n",
    "            boltz = (valuesdf[column] * valuesdf[\"Mole Fraction\"]).sum() #number\n",
    "            delta_values_sq = []\n",
    "    \n",
    "            #makes a list of the \"deviation\" for each conformer           \n",
    "            for index, row in valuesdf.iterrows(): \n",
    "                value = row[column]\n",
    "                delta_value_sq = (value - boltz)**2\n",
    "                delta_values_sq.append(delta_value_sq)\n",
    "            \n",
    "            #w is list of weights (i.e. mole fractions)\n",
    "            w = list(valuesdf[\"Mole Fraction\"])\n",
    "            wstdev = np.sqrt( (np.average(delta_values_sq, weights=w)) / (((len(w)-1)/len(w))*np.sum(w)) )\n",
    "            if len(w) == 1: #if there is only one conformer in the ensemble, set the weighted standard deviation to 0 \n",
    "                wstdev = 0\n",
    "            #np.average(delta_values_sq, weights=w) generates sum of each (delta_value_sq * mole fraction)\n",
    "            \n",
    "            values_boltz_stdev_row.append(wstdev)\n",
    "            \n",
    "            \n",
    "    valuesdf.loc[len(valuesdf)] = values_boltz_row\n",
    "    valuesdf.loc[len(valuesdf)] = values_boltz_stdev_row\n",
    "    valuesdf.loc[len(valuesdf)] = values_min_row\n",
    "    valuesdf.loc[len(valuesdf)] = values_max_row\n",
    "    valuesdf.loc[len(valuesdf)] = values_range_row\n",
    "\n",
    "    #final output format is built here:\n",
    "    explicit_order_front_columns = [\"log_name\", energy_col_header,\"∆G(Hartree)\",\"∆G(kcal/mol)\",\"e^(-∆G/RT)\",\"Mole Fraction\"]\n",
    "    \n",
    "    #reorders the dataframe using front columns defined above\n",
    "    valuesdf = valuesdf[explicit_order_front_columns + [col for col in valuesdf.columns if col not in explicit_order_front_columns and col not in values_exclude_columns]]\n",
    "    \n",
    "    #determine the index of the lowest energy conformer\n",
    "    low_e_index = valuesdf[valuesdf[\"∆G(Hartree)\"] == 0].index.tolist()\n",
    "    \n",
    "    #copy the row to a new_row with the name of the log changed to Lowest E Conformer\n",
    "    new_row = valuesdf.loc[low_e_index[0]]\n",
    "    new_row['log_name'] = \"Lowest E Conformer\"   \n",
    "    valuesdf =  valuesdf.append(new_row, ignore_index=True)\n",
    "\n",
    "#------------------------------EDIT THIS SECTION IF YOU WANT A SPECIFIC CONFORMER----------------------------------  \n",
    "    #if you want all properties for a conformer with a particular property (i.e. all properties for the Vbur_min conformer)\n",
    "    #this template can be adjusted for min/max/etc. \n",
    "    \n",
    "    #find the index for the min or max column:\n",
    "    ensemble_min_index = valuesdf[valuesdf[\"log_name\"] == \"Ensemble Minimum\"].index.tolist()\n",
    "    \n",
    "    #find the min or max value of the property (based on index above)\n",
    "    #saves the value in a list (min_value) with one entry (this is why we call min_value[0])\n",
    "    min_value = valuesdf.loc[ensemble_min_index, \"%Vbur_C4_3.0Å\"].tolist()   \n",
    "    vbur_min_index = valuesdf[valuesdf[\"%Vbur_C4_3.0Å\"] == min_value[0]].index.tolist()\n",
    "    \n",
    "    #copy the row to a new_row with the name of the log changed to Property_min_conformer\n",
    "    new_row = valuesdf.loc[vbur_min_index[0]]\n",
    "    new_row['log_name'] = \"%Vbur_C4_3.0Å_min_Conformer\"   \n",
    "    valuesdf =  valuesdf.append(new_row, ignore_index=True)\n",
    "#--------------------------------------------------------------------------------------------------------------------    \n",
    "    \n",
    "    #appends the frame to the master output\n",
    "    all_df_master = pd.concat([all_df_master, valuesdf])\n",
    "    \n",
    "    #drop all the individual conformers\n",
    "    dropindex = valuesdf[valuesdf[\"log_name\"].str.startswith(substring)].index\n",
    "    valuesdf = valuesdf.drop(dropindex)\n",
    "    valuesdf = valuesdf.reset_index(drop = True)\n",
    "    \n",
    "    #display(valuesdf)   \n",
    "    \n",
    "    #drop the columns created to determine the mole fraction and some that \n",
    "    valuesdf = valuesdf.drop(columns = explicit_order_front_columns)\n",
    "    try:\n",
    "        valuesdf = valuesdf.drop(columns = gv_extra_columns)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        valuesdf = valuesdf.drop(columns = reg_avg_columns)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "#---------------------THIS MAY NEED TO CHANGE DEPENDING ON HOW YOU LABEL YOUR COMPOUNDS------------------------------  \n",
    "    compound_name = prefix + str(compound) \n",
    "#--------------------------------------------------------------------------------------------------------------------      \n",
    "\n",
    "    properties_df = pd.DataFrame({'Compound_Name': [compound_name]})\n",
    "    \n",
    "    #builds a dataframe (for each compound) by adding summary properties as new columns\n",
    "    for (columnName, columnData) in valuesdf.iteritems():\n",
    "        #the indexes need to match the values dataframe - display it to double check if you need to make changes \n",
    "        #(uncomment the display(valuesdf) in row 124 of this cell)\n",
    "        properties_df[str(columnName) + \"_Boltz\"] = [columnData.values[0]]\n",
    "        properties_df[str(columnName) + \"_Boltz_stdev\"] = [columnData.values[1]]\n",
    "        properties_df[str(columnName) + \"_min\"] = [columnData.values[2]]\n",
    "        properties_df[str(columnName) + \"_max\"] = [columnData.values[3]]\n",
    "        properties_df[str(columnName) + \"_range\"] = [columnData.values[4]]\n",
    "        properties_df[str(columnName) + \"_low_E\"] = [columnData.values[5]]\n",
    "        \n",
    "        #if you're collecting properties for a specific conformer, add these here (note the index)\n",
    "        #example:\n",
    "        properties_df[str(columnName) + \"_V_bur_min\"] = [columnData.values[6]]\n",
    "        \n",
    "        #if you only want a table with Boltz, you can comment out the other summary properties to generate a Boltz spreadsheet\n",
    "        #of if you don't want to collect range, etc.\n",
    "    #concatenates the individual acid properties df into the master properties df\n",
    "    properties_df_master = pd.concat([properties_df_master, properties_df], axis = 0)\n",
    "\n",
    "all_df_master = all_df_master.reset_index(drop = True)\n",
    "properties_df_master = properties_df_master.reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c0d1f2",
   "metadata": {},
   "source": [
    "### Peek at your new dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eff8d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T17:00:16.188475Z",
     "start_time": "2022-04-08T17:00:15.112936Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(properties_df_master.head())\n",
    "display(all_df_master)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c987b2b6",
   "metadata": {},
   "source": [
    "### Save to Microsoft Excelᵀᴹ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a6d107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T19:54:11.339686Z",
     "start_time": "2022-03-14T19:54:11.070753Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "all_df_master.to_excel('All_Conformer_Properties_for_Ac2_to_Ac6.xlsx', index = False)\n",
    "properties_df_master.to_excel('Summary_Properties_for_Ac2_to_Ac6.xlsx', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpenv_win] *",
   "language": "python",
   "name": "conda-env-gpenv_win-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "480px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
